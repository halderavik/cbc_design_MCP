from __future__ import annotations

import csv
import io
from typing import Any, Dict, List, Optional

from conjoint_mcp.models.responses import GenerateDesignResponse


def export_design_to_csv(design_response: GenerateDesignResponse, include_metadata: bool = True) -> str:
    """
    Export design to CSV format suitable for survey platforms.
    Generates the design for all respondents with respondent_ID column.
    
    Args:
        design_response (GenerateDesignResponse): Design response to export.
        include_metadata (bool): Whether to include metadata rows.
        
    Returns:
        str: CSV content as string.
    """
    output = io.StringIO()
    writer = csv.writer(output)
    
    if include_metadata:
        # Add metadata rows
        writer.writerow(["# CBC Design Export"])
        writer.writerow(["# Generated by CBC Design Generator MCP Server"])
        writer.writerow([f"# Efficiency Score: {design_response.efficiency}"])
        writer.writerow([f"# Number of Respondents: {design_response.num_respondents}"])
        if design_response.suggested_respondents:
            writer.writerow([f"# Suggested Respondents: {design_response.suggested_respondents}"])
        if design_response.notes:
            writer.writerow([f"# Notes: {design_response.notes}"])
        writer.writerow([])  # Empty row
    
    # Write header
    if design_response.tasks:
        # Get all attribute names from first task
        first_task = design_response.tasks[0]
        if first_task.options:
            attributes = list(first_task.options[0].keys())
            header = ["respondent_ID", "Task_Index", "Option_Index"] + attributes
            writer.writerow(header)
            
            # Write data rows for all respondents
            for respondent_id in range(1, design_response.num_respondents + 1):
                for task in design_response.tasks:
                    for option_idx, option in enumerate(task.options, 1):
                        row = [respondent_id, task.task_index, option_idx]
                        for attr in attributes:
                            row.append(option.get(attr, ""))
                        writer.writerow(row)
    
    return output.getvalue()


def export_design_to_json(design_response: GenerateDesignResponse) -> str:
    """
    Export design to JSON format.
    
    Args:
        design_response (GenerateDesignResponse): Design response to export.
        
    Returns:
        str: JSON content as string.
    """
    import json
    
    export_data = {
        "metadata": {
            "efficiency": design_response.efficiency,
            "notes": design_response.notes,
            "total_tasks": len(design_response.tasks),
            "total_options": sum(len(task.options) for task in design_response.tasks),
        },
        "tasks": [
            {
                "task_index": task.task_index,
                "options": task.options,
            }
            for task in design_response.tasks
        ]
    }
    
    return json.dumps(export_data, indent=2)


def export_design_to_qualtrics_format(design_response: GenerateDesignResponse) -> str:
    """
    Export design to Qualtrics-compatible format.
    
    Args:
        design_response (GenerateDesignResponse): Design response to export.
        
    Returns:
        str: Qualtrics-compatible CSV content.
    """
    output = io.StringIO()
    writer = csv.writer(output)
    
    # Qualtrics header format
    writer.writerow(["Task", "Option", "Attribute", "Level"])
    
    # Write data in Qualtrics format
    for task in design_response.tasks:
        for option_idx, option in enumerate(task.options, 1):
            for attr_name, level_name in option.items():
                writer.writerow([task.task_index, option_idx, attr_name, level_name])
    
    return output.getvalue()


def create_design_summary(design_response: GenerateDesignResponse) -> Dict[str, Any]:
    """
    Create a summary of the design for reporting.
    
    Args:
        design_response (GenerateDesignResponse): Design response to summarize.
        
    Returns:
        Dict[str, any]: Design summary.
    """
    if not design_response.tasks:
        return {"error": "No tasks in design"}
    
    # Count attributes and levels
    first_task = design_response.tasks[0]
    if not first_task.options:
        return {"error": "No options in first task"}
    
    attributes = list(first_task.options[0].keys())
    attribute_levels = {}
    
    for attr in attributes:
        levels = set()
        for task in design_response.tasks:
            for option in task.options:
                if attr in option:
                    levels.add(option[attr])
        attribute_levels[attr] = sorted(list(levels))
    
    # Calculate statistics
    total_tasks = len(design_response.tasks)
    total_options = sum(len(task.options) for task in design_response.tasks)
    avg_options_per_task = total_options / total_tasks if total_tasks > 0 else 0
    
    return {
        "total_tasks": total_tasks,
        "total_options": total_options,
        "average_options_per_task": round(avg_options_per_task, 2),
        "attributes": attributes,
        "attribute_levels": attribute_levels,
        "efficiency_score": design_response.efficiency,
        "notes": design_response.notes,
    }
